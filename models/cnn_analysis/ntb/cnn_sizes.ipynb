{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# change this path according \n",
    "sys.path.append('/hpc/compgen/users/mpages/babe/src')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the size of the different CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad), sum(p.numel() for p in model.parameters() if not p.requires_grad), sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_bonito = nn.Sequential(\n",
    "        nn.Conv1d(\n",
    "                in_channels = 1, \n",
    "                out_channels = 4, \n",
    "                kernel_size = 5, \n",
    "                stride= 1, \n",
    "                padding=5//2, \n",
    "                bias=True\n",
    "        ),\n",
    "        nn.SiLU(),\n",
    "        nn.Conv1d(\n",
    "                in_channels = 4, \n",
    "                out_channels = 16, \n",
    "                kernel_size = 5, \n",
    "                stride= 1, \n",
    "                padding=5//2, \n",
    "                bias=True\n",
    "        ),\n",
    "        nn.SiLU(),\n",
    "        nn.Conv1d(\n",
    "                in_channels = 16, \n",
    "                out_channels = 384, \n",
    "                kernel_size = 19, \n",
    "                stride= 5, \n",
    "                padding=19//2, \n",
    "                bias=True\n",
    "        ),\n",
    "        nn.SiLU()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117480, 0, 117480)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_bonito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 384, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 500), device = device)\n",
    "y = cnn_bonito(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "padding = 1\n",
    "kernel = 3\n",
    "stride = 2\n",
    "dilation = 1\n",
    "\n",
    "cnn_catcaller = nn.Sequential(\n",
    "    nn.Conv1d(\n",
    "        in_channels=1,\n",
    "        out_channels=d_model//2,\n",
    "        kernel_size=kernel,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=False),\n",
    "    nn.BatchNorm1d(num_features=d_model//2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(\n",
    "        in_channels=d_model//2,\n",
    "        out_channels=d_model,\n",
    "        kernel_size=kernel,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=False),\n",
    "    nn.BatchNorm1d(num_features=d_model),\n",
    "    nn.ReLU()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395520, 0, 395520)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_catcaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512, 125])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 500), device = device)\n",
    "y = cnn_catcaller(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CausalCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.causalcall import CausalCallConvBlock\n",
    "\n",
    "num_blocks = 5\n",
    "num_channels = 256\n",
    "kernel_size = 3\n",
    "dilation_multiplier = 2\n",
    "dilation = 1\n",
    "\n",
    "layers = list()\n",
    "for i in range(num_blocks):\n",
    "    if i == 0:\n",
    "        layers.append(CausalCallConvBlock(kernel_size, num_channels, 1, dilation))\n",
    "    else:\n",
    "        layers.append(CausalCallConvBlock(kernel_size, num_channels, int(num_channels/2), dilation))\n",
    "    dilation *= dilation_multiplier\n",
    "\n",
    "cnn_causalcall = nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956928, 0, 956928)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_causalcall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 500])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 500), device = device)\n",
    "y = cnn_causalcall(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halcyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.halcyon import HalcyonCNNBlock, HalcyonInceptionBlock\n",
    "\n",
    "strides = [1] * 5\n",
    "num_kernels = [1, 3, 5, 7, 3]\n",
    "paddings = ['same'] * 5\n",
    "num_channels = [64, 96, 128, 160, 32]\n",
    "use_bn = [True] * 5\n",
    "\n",
    "cnn_halcyon = nn.Sequential(\n",
    "    HalcyonCNNBlock( 1, 64, 3, 2, \"valid\", True),\n",
    "    HalcyonCNNBlock(64, 64, 3, 1, \"valid\", True),\n",
    "    HalcyonCNNBlock(64, 128, 3, 1, \"valid\", True),\n",
    "    nn.MaxPool1d(3, 2),\n",
    "    HalcyonCNNBlock(128, 160, 3, 1, \"valid\", True),\n",
    "    HalcyonCNNBlock(160, 384, 3, 1, \"valid\", True),\n",
    "    nn.MaxPool1d(3, 2),\n",
    "    HalcyonInceptionBlock(384, num_channels, num_kernels, strides, paddings, use_bn, scaler = 0.8**1),\n",
    "    HalcyonInceptionBlock(382, num_channels, num_kernels, strides, paddings, use_bn, scaler = 0.8**2),\n",
    "    HalcyonInceptionBlock(304, num_channels, num_kernels, strides, paddings, use_bn, scaler = 0.8**3),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329643, 0, 1329643)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_halcyon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 243, 58])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 500), device = device)\n",
    "y = cnn_halcyon(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.mincall import MinCallConvBlock\n",
    "\n",
    "num_layers = 72\n",
    "pool_every = 24\n",
    "kernel_size = 3\n",
    "padding = 'same'\n",
    "num_channels = 64\n",
    "max_pool_kernel = 2\n",
    "\n",
    "layers = list()\n",
    "layers.append(nn.Conv1d(1, num_channels, kernel_size, 1, padding)) \n",
    "for i in range(num_layers):\n",
    "    if i % pool_every == 0 and i > 0:\n",
    "        layers.append(nn.MaxPool1d(max_pool_kernel))\n",
    "    layers.append(MinCallConvBlock(kernel_size, num_channels, num_channels, padding))\n",
    "\n",
    "cnn_mincall = nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797376, 0, 1797376)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_mincall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 125])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 500), device = device)\n",
    "y = cnn_mincall(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SACall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "kernel = 3\n",
    "maxpooling_stride = 2 \n",
    "\n",
    "cnn_sacall = nn.Sequential(\n",
    "    nn.Conv1d(1, d_model//2, kernel, 1, 1, bias=False),\n",
    "    nn.BatchNorm1d(d_model//2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel, maxpooling_stride, 1),\n",
    "    nn.Conv1d(d_model//2, d_model, kernel, 1, 1, bias=False),\n",
    "    nn.BatchNorm1d(d_model),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel, maxpooling_stride, 1),\n",
    "    nn.Conv1d(d_model, d_model, kernel, 1, 1, bias=False),\n",
    "    nn.BatchNorm1d(d_model),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel, maxpooling_stride, 1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296576, 0, 296576)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_sacall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 63])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 500), device = device)\n",
    "y = cnn_sacall(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URNano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.urnano import URNetDownBlock, URNetFlatBlock, URNetUpBlock, URNet\n",
    "\n",
    "padding = 'same'\n",
    "stride = 1\n",
    "n_channels = [64, 128, 256, 512]\n",
    "kernel = 11\n",
    "maxpooling = [2, 2, 2] # in the github json it is [3, 2, 2], changed because we use even number segments\n",
    "\n",
    "down = nn.ModuleList([URNetDownBlock(1, n_channels[0], kernel, maxpooling[0], stride, padding),\n",
    "                        URNetDownBlock(n_channels[0], n_channels[1], 3, maxpooling[1], stride, padding),\n",
    "                        URNetDownBlock(n_channels[1], n_channels[2], 3, maxpooling[2], stride, padding)])\n",
    "flat = nn.ModuleList([URNetFlatBlock(n_channels[2], n_channels[3], 3, stride, padding)])\n",
    "up = nn.ModuleList([URNetUpBlock(n_channels[3], n_channels[2], 3, maxpooling[2], maxpooling[2], stride, padding), \n",
    "                    URNetUpBlock(n_channels[2], n_channels[1], 3, maxpooling[1], maxpooling[1], stride, padding),\n",
    "                    URNetUpBlock(n_channels[1], n_channels[0], 3, maxpooling[0], maxpooling[0], stride, padding)])\n",
    "\n",
    "cnn_urnano = nn.Sequential(URNet(down, flat, up), \n",
    "                            nn.Conv1d(n_channels[0], n_channels[0], 3, stride, padding), \n",
    "                            nn.BatchNorm1d(n_channels[0]), \n",
    "                            nn.ReLU()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3510464, 0, 3510464)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(cnn_urnano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 4000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/compgen/users/mpages/software/miniconda3/envs/babe/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((64, 1, 4000), device = device)\n",
    "y = cnn_urnano(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
